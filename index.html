<!DOCTYPE html>
<html>

  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta http-equiv="X-UA-Compatible" content="IE=edge">

<title>

  Yuxiang  Cui


</title>
<meta name="description" content="Zhejiang University">

<!-- Open Graph -->


<!-- Bootstrap & MDB -->
<link href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/css/bootstrap.min.css" rel="stylesheet" integrity="sha512-MoRNloxbStBcD8z3M/2BmnT+rg4IsMxPkXaGh2zD6LGNNFE80W3onsAhRcMAMrSoyWL9xD7Ert0men7vR8LUZg==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/css/mdb.min.css" integrity="sha512-RO38pBRxYH3SoOprtPTD86JFOclM51/XTIdEPh5j8sj4tp8jmQIx26twG52UaLi//hQldfrh7e51WzP9wuP32Q==" crossorigin="anonymous" />

<!-- Fonts & Icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css"  integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.9.0/css/academicons.min.css" integrity="sha512-W4yqoT1+8NLkinBLBZko+dFB2ZbHsYLDdr50VElllRcNt2Q4/GSs6u71UHKxB7S6JEMCp5Ve4xjh3eGQl/HRvg==" crossorigin="anonymous">
<link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

<!-- Code Syntax Highlighting -->
<link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

<!-- Styles -->

<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ü§ñ</text></svg>">

<link rel="stylesheet" href="/assets/css/main.css">
<link rel="canonical" href="/">

<!-- JQuery -->
<!-- jQuery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>


<!-- Theming-->

<script src="/assets/js/theme.js"></script>
<script src="/assets/js/dark_mode.js"></script>






    
<!-- MathJax -->
<script type="text/javascript">
  window.MathJax = {
    tex: {
      tags: 'ams'
    }
  };
</script>
<script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
<script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>


  </head>

  <body class="fixed-top-nav ">

    <!-- Header -->

    <header>

    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
    <div class="container">
      
      <!-- Navbar Toggle -->
      <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar top-bar"></span>
        <span class="icon-bar middle-bar"></span>
        <span class="icon-bar bottom-bar"></span>
      </button>
      <div class="collapse navbar-collapse text-right" id="navbarNav">
        <ul class="navbar-nav ml-auto flex-nowrap">
          <!-- About -->
          <li class="nav-item active">
            <a class="nav-link" href="/">
              about
              
                <span class="sr-only">(current)</span>
              
            </a>
          </li>
          
          <!-- Blog -->
          <li class="nav-item ">
            <a class="nav-link" href="/blog/">
              blog
              
            </a>
          </li>
          
          <!-- Other pages -->
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/projects/">
                projects
                
              </a>
          </li>
          
          
          
          
          
          <li class="nav-item ">
              <a class="nav-link" href="/publications/">
                publications
                
              </a>
          </li>
          
          
          
          
            <div class = "toggle-container">
              <a id = "light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
              </a>
            </div>
          
        </ul>
      </div>
    </div>
  </nav>

</header>


    <!-- Content -->

    <div class="container mt-5">
      <div class="post">

  <header class="post-header">
    <h1 class="post-title">
     <span class="font-weight-bold">Yuxiang</span>  Cui
    </h1>
     <p class="desc">Graduate Student | Robotics Lab | Department of Control Science and Engineering | Zhejiang University</p>
  </header>

  <article>
    
    <div class="profile float-right">
      
        <img class="img-fluid z-depth-1 rounded" src="/assets/img/myself/myself_1.jpg">
      
      
        <div class="address">
          <p>Hangzhou, Zhejiang, China</p>

        </div>
      
    </div>
    

    <div class="clearfix">
      <p>Research Interests:</p>
<ul>
  <li>Multi-robot Navigation</li>
  <li>Reinforcement Learning / Multi-agent Reinforcement Learning</li>
</ul>

<p>Please visit my own <a href="https://space.bilibili.com/362532146">Bilibili Channel</a> for videos.</p>

<p>Please visit our Lab‚Äôs <a href="https://www.youtube.com/channel/UCkGsUj95tueXDxf5JEhiYZQ">YouTube Channel</a> and <a href="https://space.bilibili.com/544651460">Bilibili Channel</a> for more information.</p>

    </div>

    
      <div class="news">
  <h2>news</h2>
  
    <div class="table-responsive">
      <table class="table table-sm table-borderless">
      
      
        <tr>
          <th scope="row">Sep 15, 2021</th>
          <td>
            
              One new paper submitted in ICRA 2022: ‚ÄúLearning Observation-Based Certifiable Safe Policy for Decentralized Multi-Robot Navigation‚Äù.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Apr 30, 2021</th>
          <td>
            
              One RCAR 2021 paper accepted: ‚ÄúSocially-Aware Multi-Agent Following with 2D Laser Scans via Deep Reinforcement Learning and Potential Field‚Äù.

            
          </td>
        </tr>
      
        <tr>
          <th scope="row">Mar 1, 2021</th>
          <td>
            
              One ICRA 2021 paper accepted: ‚ÄúLearning World Transition Model for Socially Aware Robot Navigation‚Äù.

            
          </td>
        </tr>
      
      </table>
    </div>
  
</div>

    

    
      <div class="publications">
  <h2>selected publications</h2>
  <ol class="bibliography"><li><div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/img/first_img/ICRA2021.png">
    
    </div>

  <div id="cui2020learning" class="col-sm-8">
    
      <div class="title">Learning World Transition Model for Socially Aware Robot Navigation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Cui, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhang, Haodong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Yue,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Xiong, Rong
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2011.03922</em>
      
      
        2020
      
      
        Accepted in ICRA 2021
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2011.03922" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://arxiv.org/abs/2011.03922" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
      <a href="https://github.com/ZJU-Robotics-Lab/model-based-social-navigation" class="btn btn-sm z-depth-0" role="button" target="_blank">Code</a>
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Moving in dynamic pedestrian environments is one of the important requirements for autonomous mobile robots. We present a model-based reinforcement learning approach for robots to navigate through crowded environments. The navigation policy is trained with both real interaction data from multi-agent simulation and virtual data from a deep transition model that predicts the evolution of surrounding dynamics of mobile robots. A reward function considering social conventions is designed to guide the training of the policy. Specifically, the policy model takes laser scan sequence and robot‚Äôs own state as input and outputs steering command. The laser sequence is further transformed into stacked local obstacle maps disentangled from robot‚Äôs ego motion to separate the static and dynamic obstacles, simplifying the model training. We observe that the policy using our method can be trained with significantly less real interaction data in simulator but achieve similar level of success rate in social navigation tasks compared with other methods. Experiments are conducted in multiple social scenarios both in simulation and on real robots, the learned policy can guide the robots to the final targets successfully in a socially compliant manner.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/img/first_img/RCAR2021.png">
    
    </div>

  <div id="cui2021socially" class="col-sm-8">
    
      <div class="title">Socially-Aware Multi-Agent Following with 2D Laser Scans via Deep Reinforcement Learning and Potential Field</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Cui, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Huang, Xiaolong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Yue,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Xiong, Rong
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>In 2021 IEEE International Conference on Real-time Computing and Robotics (RCAR)</em>
      
      
        2021
      
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2109.01874" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://ieeexplore.ieee.org/document/9517362" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Target following in dynamic pedestrian environments is an important task for mobile robots. However, it is challenging to keep tracking the target while avoiding collisions in crowded environments, especially with only one robot. In this paper, we propose a multi-agent method for an arbitrary number of robots to follow the target in a socially-aware manner using only 2D laser scans. The multi-agent following problem is tackled by utilizing the complementary strengths of both reinforcement learning and potential field, in which the reinforcement learning part handles local interactions while navigating to the goals assigned by the potential field. Specifically, with the help of laser scans in obstacle map representation, the learning-based policy can help the robots avoid collisions with both static obstacles and dynamic obstacles like pedestrians in advance, namely socially aware.While the formation control and goal assignment for each robot is obtained from a target-centered potential field constructed using aggregated state information from all the following robots. Experiments are conducted in multiple settings, including random obstacle distributions and different numbers of robots. Results show that our method works successfully in unseen dynamic environments. The robots can follow the target in a socially compliant manner with only 2D laser scans.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3">
    
      <img class="img-fluid" src="/assets/img/first_img/ICRA2022.png">
    
    </div>

  <div id="cui2021learning" class="col-sm-8">
    
      <div class="title">Learning Observation-Based Certifiable Safe Policy for Decentralized Multi-Robot Navigation</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                <em>Cui, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Lin, Longzhong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Huang, Xiaolong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Zhang, Dongkun,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Yue,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Xiong, Rong
                
              
            
          
        
      </div>

      <div class="periodical">
      
      
        2021
      
      
        Under Review
      
      </div>
    

    <div class="links">
    
      <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a>
    
    
      <a href="http://arxiv.org/abs/2109.07760" class="btn btn-sm z-depth-0" role="button" target="_blank">arXiv</a>
    
    
    
      <a href="https://arxiv.org/abs/2109.07760" class="btn btn-sm z-depth-0" role="button" target="_blank">HTML</a>
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    
    <div class="abstract hidden">
      <p>Safety is of great importance in multi-robot navigation problems. In this paper, we propose a control barrier function (CBF) based optimizer that ensures robot safety with both high probability and flexibility, using only sensor measurement. The optimizer takes action commands from the policy network as initial values and then provides refinement to drive the potentially dangerous ones back into safe regions. With the help of a deep transition model that predicts the evolution of surrounding dynamics and the consequences of different actions, the CBF module can guide the optimization in a reasonable time horizon. We also present a novel joint training framework that improves the cooperation between the Reinforcement Learning (RL) based policy and the CBF-based optimizer both in training and inference procedures by utilizing reward feedback from the CBF module. We observe that the policy using our method can achieve a higher success rate while maintaining the safety of multiple robots in significantly fewer episodes compared with other methods. Experiments are conducted in multiple scenarios both in simulation and the real world, the results demonstrate the effectiveness of our method in maintaining the safety of multi-robot navigation.</p>
    </div>
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li>
<li><div class="row">
  <div class="col-sm-3">
    
    </div>

  <div id="zhang2021human" class="col-sm-8">
    
      <div class="title">Human-Robot Motion Retargeting via Neural Latent Optimization</div>
      <div class="author">
        
          
          
          
          
          
          
            
              
                
                  Zhang, Haodong,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Li, Weijie,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Liang, Yuwei,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Chen, Zexi,
                
              
            
          
        
          
          
          
          
          
          
            
              
                <em>Cui, Yuxiang</em>,
              
            
          
        
          
          
          
          
          
          
            
              
                
                  Wang, Yue,
                
              
            
          
        
          
          
          
          
          
          
            
              
                
                  and Xiong, Rong
                
              
            
          
        
      </div>

      <div class="periodical">
      
        <em>arXiv preprint arXiv:2103.08882</em>
      
      
        2021
      
      
      </div>
    

    <div class="links">
    
    
    
    
    
    
    
    
    
    
    
    </div>

    <!-- Hidden abstract block -->
    

    <!-- Hidden bibtex block -->
    
  </div>
</div>
</li></ol>
</div>

    

    
    <div class="social">
      <div class="contact-icons">
        <a href="mailto:%79%75%78%69%61%6E%67%63%75%69@%7A%6A%75.%65%64%75.%63%6E"><i class="fas fa-envelope"></i></a>

<a href="https://scholar.google.com/citations?user=Yuxiang Cui" target="_blank" title="Google Scholar"><i class="ai ai-google-scholar"></i></a>


<a href="https://github.com/YuxiangCui" target="_blank" title="GitHub"><i class="fab fa-github"></i></a>












      </div>
      <div class="contact-note">Feel free to contract me !
</div>
    </div>
    
  </article>

</div>

    </div>

    <!-- Footer -->

    
<footer class="fixed-bottom">
  <div class="container mt-0">
    &copy; Copyright 2021 Yuxiang  Cui.
    Hello from YuxiangCui
    
    
  </div>
</footer>



  </body>

  <!-- Bootsrap & MDB scripts -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/2.4.4/umd/popper.min.js" integrity="sha512-eUQ9hGdLjBjY3F41CScH3UX+4JDSI9zXeroz7hJ+RteoCaY+GP/LDoM8AO+Pt+DRFw3nXqsjh9Zsts8hnYv8/A==" crossorigin="anonymous"></script>
<script src="https://stackpath.bootstrapcdn.com/bootstrap/4.5.2/js/bootstrap.min.js" integrity="sha512-M5KW3ztuIICmVIhjSqXe01oV2bpe248gOxqmlcYrEzAvws7Pw3z6BK0iGbrwvdrUQUhi3eXgtxp5I8PDo9YfjQ==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mdbootstrap/4.19.1/js/mdb.min.js" integrity="sha512-Mug9KHKmroQFMLm93zGrjhibM2z2Obg9l6qFG2qKjXEXkMp/VDkI4uju9m4QKPjWSwQ6O2qzZEnJDEeCw0Blcw==" crossorigin="anonymous"></script>

  
<!-- Mansory & imagesLoaded -->
<script defer src="https://unpkg.com/masonry-layout@4/dist/masonry.pkgd.min.js"></script>
<script defer src="https://unpkg.com/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
<script defer src="/assets/js/mansory.js" type="text/javascript"></script>


  


<!-- Medium Zoom JS -->
<script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
<script src="/assets/js/zoom.js"></script>


<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


</html>
